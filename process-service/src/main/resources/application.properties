spring.application.name=process-service
server.port=8081

## POSTGRES
spring.datasource.url=jdbc:postgresql://localhost:5432/batch_integration
spring.datasource.username=postgres
spring.datasource.password=123456
spring.datasource.driver-class-name=org.postgresql.Driver
# Aumenta o número máximo de conexões simultâneas
spring.datasource.hikari.maximum-pool-size=20
spring.datasource.hikari.minimum-idle=10
spring.datasource.hikari.idle-timeout=30000

## Kafka Consumer
spring.kafka.bootstrap-servers=localhost:9092
spring.kafka.consumer.group-id=batch-integration-group
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.auto-offset-reset=earliest
# Desabilitar auto-commit, pois processamos manualmente
spring.kafka.listener.ack-mode=manual
spring.kafka.consumer.enable-auto-commit=false
# Paralelismo (quantidade de threads de consumo em paralelo)
spring.kafka.listener.concurrency=6
# Tamanho máximo do buffer do consumidor
spring.kafka.consumer.properties.fetch.max.bytes=52428800
# Tamanho máximo da requisição
spring.kafka.consumer.properties.max.partition.fetch.bytes=10485760
# Timeout maior para processamentos pesados
spring.kafka.consumer.properties.session.timeout.ms=30000
# Intervalo de heartbeat para manter sessão ativa
spring.kafka.consumer.heartbeat-interval=9000
# Limite de tempo entre commits (como usamos ack manual, é só precaução)
spring.kafka.consumer.properties.max.poll.interval.ms=600000
# Quantidade máxima de registros por poll (ajustar conforme memória)
spring.kafka.consumer.max-poll-records=50000
# Tempo máximo de espera por mensagens (ms)
spring.kafka.consumer.properties.fetch.max.wait.ms=500



